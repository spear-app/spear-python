# -*- coding: utf-8 -*-
"""SoundDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nq4dtcO_7h848ezWrGydteJ7WlzFXIqq
"""

pip install librosa

!pip uninstall keras -y
!pip uninstall keras-nightly -y
!pip uninstall keras-Preprocessing -y
!pip uninstall keras-vis -y
!pip uninstall h5py -y
!pip uninstall tensorflow

!pip install keras==2.0.8
!pip install h5py==2.10.0
!pip install tensorflow==1.13.2
!pip install  keras-preprocessing

# Load imports

import IPython.display as ipd
import librosa
import librosa.display
import matplotlib.pyplot as plt
import os
import pandas as pd
from helpers.wavfilehelper import WavFileHelper
from scipy.io import wavfile as wav
import numpy as np
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
# split the dataset 
from sklearn.model_selection import train_test_split 
from tensorflow.keras.optimizers import Adam
from sklearn import metrics 
from datetime import datetime 
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, MaxPooling2D
from keras.utils import np_utils
from keras.callbacks import ModelCheckpoint 
from tensorflow.keras.models import load_model

path_of_the_directory= 'dataset/'
###############################
for filename in os.listdir(path_of_the_directory):
    f = os.path.join(path_of_the_directory,filename)
    if os.path.isfile(f):
        print(f)
        plt.figure(figsize=(12,4))
        data,sample_rate = librosa.load(f)
        _ = librosa.display.waveplot(data,sr=sample_rate)
        ipd.Audio(f)

wavfilehelper = WavFileHelper()

audiodata = []
path_of_the_directory= 'dataset/'

for filename in os.listdir(path_of_the_directory):
    f = os.path.join(path_of_the_directory,filename)
    if os.path.isfile(f):
        data = wavfilehelper.read_file_properties(f)
        audiodata.append(data)

# Convert into a Panda dataframe
audio_dataframe = pd.DataFrame(audiodata, columns=['num_channels','sample_rate','bit_depth'])

# num of channels 
print("number of channels:")
print(audio_dataframe.num_channels.value_counts(normalize=True))
print("sample rate:")
print(audio_dataframe.sample_rate.value_counts(normalize=True))
# bit depth
print("bit depth:")
print(audio_dataframe.bit_depth.value_counts(normalize=True))

filename = 'dataset/knock.wav' 

librosa_audio, librosa_sample_rate = librosa.load(filename) 
scipy_sample_rate, scipy_audio = wav.read(filename) 

print('Original sample rate:', scipy_sample_rate) 
print('Librosa sample rate:', librosa_sample_rate) 

print('Original audio file min~max range:', np.min(scipy_audio), 'to', np.max(scipy_audio))
print('Librosa audio file min~max range:', np.min(librosa_audio), 'to', np.max(librosa_audio))

import matplotlib.pyplot as plt

# Original audio with 2 channels 
plt.figure(figsize=(12, 4))
plt.plot(scipy_audio)
# Librosa audio with channels merged 
plt.figure(figsize=(12, 4))
plt.plot(librosa_audio)

mfccs = librosa.feature.mfcc(y=librosa_audio, sr=librosa_sample_rate, n_mfcc=40)
print(mfccs.shape)

librosa.display.specshow(mfccs, sr=librosa_sample_rate, x_axis='time')

def extract_features(file_name):
   
    try:
        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') 
        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)
        mfccsscaled = np.mean(mfccs.T,axis=0)
        
    except Exception as e:
        print("Error encountered while parsing file: ", file_name)
        return None 
     
    return mfccsscaled

datasetpath = 'dataset/'
metadata = pd.read_csv('Sounds.csv')
features = []

# Extract the features of all the files
for index, row in metadata.iterrows():
    
    file_name = 'dataset/'+ str(row["filename"])
    
    class_label = row["Label"]
    data = extract_features(file_name)
    
    features.append([data, class_label])

# Convert into a Panda dataframe 
features_dataframe = pd.DataFrame(features, columns=['feature','class_label'])

print('Finished feature extraction from ', len(features_dataframe), ' files')

# Conversion into numpy arrays
X = np.array(features_dataframe.feature.tolist())
y = np.array(features_dataframe.class_label.tolist())

# Encode the classification labels
le = LabelEncoder()
yy = to_categorical(le.fit_transform(y))

x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.1, random_state = 42)

# Commented out IPython magic to ensure Python compatibility.
### store the preprocessed data for use in the next notebook

# %store x_train 
# %store x_test 
# %store y_train 
# %store y_test 
# %store yy 
# %store le

# Commented out IPython magic to ensure Python compatibility.
# %store -r x_train 
# %store -r x_test 
# %store -r y_train 
# %store -r y_test 
# %store -r yy 
# %store -r le

number_of_labels = yy.shape[1]
filter_size = 2

# Construct model 
model = Sequential()

model.add(Dense(256, input_shape=(40,)))
model.add(Activation('relu'))
model.add(Dropout(0.5))

model.add(Dense(256))
model.add(Activation('relu'))
model.add(Dropout(0.5))

model.add(Dense(number_of_labels))
model.add(Activation('softmax'))

# Compile the model
model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')

# Display model architecture summary 
model.summary()

# Calculate pre-training accuracy 
score = model.evaluate(x_test, y_test, verbose=0)
accuracy = 100*score[1]

print("Pre-training accuracy: %.4f%%" % accuracy)

import random
num_epochs = 29
num_batch_size = 10

checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.basic_mlp.hdf5', verbose=1, save_best_only=True)
start = datetime.now()
for i in range(6):
  x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state =random. randint(10, 42))
  print(x_train)
  history= model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), callbacks=[checkpointer], verbose=1)
  plt.plot(history.history['val_loss'])
  plt.title('Validation loss history')
  plt.ylabel('Loss value')
  plt.xlabel('No. epoch')
  plt.show()

duration = datetime.now() - start
print("Training completed in time: ", duration)

# Evaluating the model on the training and testing set
score = model.evaluate(x_train, y_train, verbose=0)
print("Training Accuracy: ", score[1])

score = model.evaluate(x_test, y_test, verbose=0)
print("Testing Accuracy: ", score[1])

def extract_feature(file_name):
   
    try:
        audio_data, sample_rate = librosa.load(file_name, res_type='kaiser_fast') 
        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=40)
        mfccsscaled = np.mean(mfccs.T,axis=0)
        
    except Exception as e:
        print("Error encountered while parsing file: ", file_name)
        return None, None

    return np.array([mfccsscaled])

def print_prediction(file_name):
    prediction_feature = extract_feature(file_name) 

    predicted_vector = model.predict_classes(prediction_feature)
    predicted_class = le.inverse_transform(predicted_vector) 
    print("The predicted class is:", predicted_class[0], '\n') 

    predicted_proba_vector = model.predict_proba(prediction_feature) 
    predicted_proba = predicted_proba_vector[0]
    for i in range(len(predicted_proba)): 
        category = le.inverse_transform(np.array([i]))
        print(category[0], "\t\t : ", format(predicted_proba[i], '.32f') )

# import tensorflow as tf
# print(tf.__version__)

# Class: Air Conditioner
print(y)
filename = 'dataset/knock.wav' 
print_prediction(filename)